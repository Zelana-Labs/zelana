use ark_bn254::{Fr, G1Affine, G1Projective};
use ark_ec::{AffineRepr, CurveGroup};
use ark_ff::PrimeField;
use ark_serialize::{CanonicalDeserialize, CanonicalSerialize};
use sha2::{Digest, Sha256};

use crate::errors::ProverError;
use crate::shamir::lagrange_coefficient;

/// Public parameters for hash preimage circuit
#[derive(Debug, Clone, CanonicalSerialize, CanonicalDeserialize)]
pub struct HashPublicParams {
    /// Generator point for the group
    pub generator: G1Affine,
    /// Target hash that we're proving we know the preimage for
    pub target_hash: Vec<u8>,
    /// Number of nodes
    pub num_nodes: usize,
    /// Threshold needed
    pub threshold: usize,
}

/// Commitment generated by a node in Phase 1
#[derive(Debug, Clone, CanonicalSerialize, CanonicalDeserialize)]
pub struct HashCommitment {
    /// Node ID
    pub node_id: usize,
    /// Commitment value (g^r where r is random nonce)
    pub value: G1Affine,
}

/// Proof fragment from a node in Phase 3
#[derive(Debug, Clone, CanonicalSerialize, CanonicalDeserialize)]
pub struct HashProofFragment {
    /// Node ID
    pub node_id: usize,
    /// Response value (z = r + c * share_hash)
    pub response: Fr,
}

/// Complete distributed proof for hash preimage
#[derive(Debug, Clone, CanonicalSerialize, CanonicalDeserialize)]
pub struct HashPreimageProof {
    /// Aggregated commitment
    pub commitment: G1Affine,
    /// Challenge
    pub challenge: Fr,
    /// Aggregated response
    pub response: Fr,
    /// Target hash (public)
    pub target_hash: Vec<u8>,
    /// Generator used
    pub generator: G1Affine,
}

/// Compute SHA-256 hash of input bytes
pub fn compute_sha256(input: &[u8]) -> Vec<u8> {
    let mut hasher = Sha256::new();
    hasher.update(input);
    hasher.finalize().to_vec()
}

/// Convert hash bytes to field element (for use in proof)
pub fn hash_to_field(hash: &[u8]) -> Fr {
    // Take first 31 bytes to stay within field modulus
    let mut bytes = [0u8; 32];
    let len = hash.len().min(31);
    bytes[..len].copy_from_slice(&hash[..len]);
    Fr::from_le_bytes_mod_order(&bytes)
}

/// Generate Fiat-Shamir challenge for hash preimage proof
pub fn generate_challenge(
    generator: &G1Affine,
    target_hash: &[u8],
    commitments: &[HashCommitment],
) -> Result<Fr, ProverError> {
    let mut hasher = Sha256::new();

    // Hash generator
    let mut gen_bytes = Vec::new();
    generator
        .serialize_compressed(&mut gen_bytes)
        .map_err(|e| ProverError::SerializationError(e.to_string()))?;
    hasher.update(&gen_bytes);

    // Hash target hash
    hasher.update(target_hash);

    // Hash all commitments
    for commitment in commitments {
        let mut commit_bytes = Vec::new();
        commitment
            .value
            .serialize_compressed(&mut commit_bytes)
            .map_err(|e| ProverError::SerializationError(e.to_string()))?;
        hasher.update(&commit_bytes);
    }

    let hash = hasher.finalize();
    Ok(hash_to_field(&hash))
}

/// Aggregate commitments using Lagrange interpolation
pub fn aggregate_commitments(commitments: &[HashCommitment]) -> Result<G1Affine, ProverError> {
    if commitments.is_empty() {
        return Err(ProverError::InsufficientFragments { needed: 1, got: 0 });
    }

    // Extract x-coordinates (node IDs)
    let x_coords: Vec<Fr> = commitments
        .iter()
        .map(|c| Fr::from((c.node_id + 1) as u64))
        .collect();

    // Aggregate: C = Σ(λᵢ · Cᵢ)
    let mut aggregated = G1Projective::default();

    for (i, commitment) in commitments.iter().enumerate() {
        let lambda = lagrange_coefficient(&x_coords, i);
        let weighted = commitment.value.into_group() * lambda;
        aggregated += weighted;
    }

    Ok(aggregated.into_affine())
}

/// Aggregate proof fragments using Lagrange interpolation
pub fn aggregate_fragments(
    fragments: &[HashProofFragment],
    threshold: usize,
) -> Result<Fr, ProverError> {
    if fragments.len() < threshold {
        return Err(ProverError::InsufficientFragments {
            needed: threshold,
            got: fragments.len(),
        });
    }

    // Extract x-coordinates (node IDs)
    let x_coords: Vec<Fr> = fragments
        .iter()
        .map(|f| Fr::from((f.node_id + 1) as u64))
        .collect();

    // Aggregate: z = Σ(λᵢ · zᵢ)
    let mut aggregated = Fr::from(0u64);

    for (i, fragment) in fragments.iter().enumerate() {
        let lambda = lagrange_coefficient(&x_coords, i);
        aggregated += lambda * fragment.response;
    }

    Ok(aggregated)
}

/// Verify a hash preimage proof
pub fn verify_proof(proof: &HashPreimageProof) -> Result<bool, ProverError> {
    // Verification equation: g^z = C · g^(c * H(target))
    // Where H(target) is the hash converted to field element

    let generator_proj: G1Projective = proof.generator.into_group();

    // Compute left side: g^z
    let left = generator_proj * proof.response;

    // Compute right side: C · g^(c * H(target))
    let target_field = hash_to_field(&proof.target_hash);
    let challenge_hash = proof.challenge * target_field;
    let right = proof.commitment.into_group() + (generator_proj * challenge_hash);

    Ok(left.into_affine() == right.into_affine())
}

#[cfg(test)]
mod tests {
    use super::*;
    use ark_std::{test_rng, UniformRand};

    #[test]
    fn test_hash_to_field() {
        use ark_std::Zero;
        let input = b"hello world";
        let hash = compute_sha256(input);
        let field_elem = hash_to_field(&hash);
        assert!(!field_elem.is_zero());
    }

    #[test]
    fn test_compute_sha256() {
        let input = b"test";
        let hash = compute_sha256(input);
        assert_eq!(hash.len(), 32);

        // Same input should give same hash
        let hash2 = compute_sha256(input);
        assert_eq!(hash, hash2);
    }

    #[test]
    fn test_generate_challenge() {
        let mut rng = test_rng();
        let generator = G1Affine::rand(&mut rng);
        let target_hash = compute_sha256(b"secret");

        let commitment = HashCommitment {
            node_id: 0,
            value: G1Affine::rand(&mut rng),
        };

        let challenge = generate_challenge(&generator, &target_hash, &[commitment]);
        assert!(challenge.is_ok());
    }

    #[test]
    fn test_aggregate_commitments() {
        let mut rng = test_rng();

        let commitments = vec![
            HashCommitment {
                node_id: 0,
                value: G1Affine::rand(&mut rng),
            },
            HashCommitment {
                node_id: 1,
                value: G1Affine::rand(&mut rng),
            },
        ];

        let result = aggregate_commitments(&commitments);
        assert!(result.is_ok());
    }
}
